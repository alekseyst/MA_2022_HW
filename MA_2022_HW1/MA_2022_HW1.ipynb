{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da363495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import nltk\n",
    "import pymorphy2\n",
    "import jsonlines\n",
    "import random\n",
    "from collections import Counter\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1bb5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задание 1\n",
    "\n",
    "with open('Labirint_otrazheniy.txt', encoding='utf-8') as f:\n",
    "    novel_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564a4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задание 2\n",
    "\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4940f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_lemmas = m.lemmatize(novel_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e700aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Labirint_otrazheniy_lemmatized.txt', 'w', encoding='utf-8') as f_w:\n",
    "    f_w.write(''.join(novel_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cea9f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aleksey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/aleksey/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Задание 3\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32059bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_tokens = nltk.word_tokenize(novel_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc0decd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ee92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('novel_anapyzed.jsonl', mode='w') as writer:\n",
    "    for token in novel_tokens:\n",
    "        token_parsed = morph.parse(token)[0]\n",
    "        writer.write({\"lemma\": token_parsed.normal_form, \"word\": token, \"pos\": token_parsed.tag.POS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1a98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задание 4\n",
    "\n",
    "pos_counter = Counter()\n",
    "adv_counter = Counter()\n",
    "verb_counter = Counter()\n",
    "\n",
    "with jsonlines.open('novel_anapyzed.jsonl', mode='r') as reader:\n",
    "    for line in reader:\n",
    "        pos_counter += Counter([line['pos']])\n",
    "        if line['pos'] == 'ADVB':\n",
    "            adv_counter += Counter([line['lemma']])\n",
    "        elif line['pos'] == 'VERB':\n",
    "            verb_counter += Counter([line['lemma']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2332ca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN 0.2708607591879129\n",
      "VERB 0.14649935385693064\n",
      "ADJF 0.10008574982789648\n",
      "PREP 0.0997596589330789\n",
      "NPRO 0.09014601625623497\n",
      "CONJ 0.08382951484921315\n",
      "ADVB 0.06711433712967547\n",
      "PRCL 0.0581045664802715\n",
      "INFN 0.03170328144059711\n",
      "PRTF 0.011207864829285378\n",
      "GRND 0.008526673027452022\n",
      "ADJS 0.008164349810988056\n",
      "PRED 0.007331006413120932\n",
      "NUMR 0.006823753910071378\n",
      "COMP 0.003925168178359642\n",
      "PRTS 0.0036715419268348653\n",
      "INTJ 0.0022464039420765952\n"
     ]
    }
   ],
   "source": [
    "all_poses = sum(pos_counter.values()) - pos_counter[None]\n",
    "\n",
    "for pos in sorted(pos_counter, key=pos_counter.get, reverse=True):\n",
    "    if pos == None:\n",
    "        continue\n",
    "    print(pos, pos_counter[pos] / all_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5967b863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ещё', 243),\n",
       " ('очень', 180),\n",
       " ('уже', 180),\n",
       " ('только', 168),\n",
       " ('потом', 137),\n",
       " ('ничего', 119),\n",
       " ('сейчас', 118),\n",
       " ('здесь', 100),\n",
       " ('там', 91),\n",
       " ('где', 85),\n",
       " ('теперь', 79),\n",
       " ('что-то', 78),\n",
       " ('почему', 77),\n",
       " ('хорошо', 72),\n",
       " ('рядом', 66),\n",
       " ('всегда', 61),\n",
       " ('уж', 59),\n",
       " ('слишком', 58),\n",
       " ('почти', 57),\n",
       " ('тогда', 57)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257dc73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('быть', 459),\n",
       " ('говорить', 389),\n",
       " ('мочь', 367),\n",
       " ('знать', 211),\n",
       " ('спрашивать', 147),\n",
       " ('смотреть', 146),\n",
       " ('кивать', 126),\n",
       " ('идти', 122),\n",
       " ('хотеть', 121),\n",
       " ('стоить', 119),\n",
       " ('начинать', 108),\n",
       " ('сказать', 102),\n",
       " ('понимать', 94),\n",
       " ('казаться', 81),\n",
       " ('шептать', 76),\n",
       " ('стать', 72),\n",
       " ('видеть', 72),\n",
       " ('выходить', 63),\n",
       " ('ждать', 62),\n",
       " ('отвечать', 61)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cab9d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задание 5\n",
    "\n",
    "novel_lemmas_nopunct = ''.join(novel_lemmas).translate(str.maketrans('', '', punctuation + '—»«…'))\n",
    "novel_tokens_lemmas_nopunct = nltk.word_tokenize(novel_lemmas_nopunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb6e4e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('я', 'не'), 244),\n",
       " (('говорить', 'я'), 142),\n",
       " (('мочь', 'быть'), 132),\n",
       " (('и', 'я'), 104),\n",
       " (('в', 'глубина'), 102),\n",
       " (('смотреть', 'на'), 98),\n",
       " (('у', 'я'), 95),\n",
       " (('и', 'не'), 91),\n",
       " (('не', 'знать'), 90),\n",
       " (('что', 'я'), 81),\n",
       " (('в', 'виртуальность'), 79),\n",
       " (('без', 'лицо'), 79),\n",
       " (('человек', 'без'), 77),\n",
       " (('он', 'не'), 73),\n",
       " (('я', 'и'), 72),\n",
       " (('но', 'я'), 71),\n",
       " (('на', 'я'), 71),\n",
       " (('не', 'мочь'), 70),\n",
       " (('я', 'в'), 69),\n",
       " (('это', 'не'), 62),\n",
       " (('не', 'быть'), 60),\n",
       " (('то', 'что'), 59),\n",
       " (('спрашивать', 'я'), 57),\n",
       " (('а', 'я'), 55),\n",
       " (('ты', 'не'), 54)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_lemmas_bigrams = nltk.bigrams(novel_tokens_lemmas_nopunct)\n",
    "novel_lemmas_bigrams_stats = Counter(novel_lemmas_bigrams)\n",
    "\n",
    "novel_lemmas_bigrams_stats.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f4fd9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('человек', 'без', 'лицо'), 77),\n",
       " (('смотреть', 'на', 'я'), 27),\n",
       " (('я', 'не', 'твой'), 18),\n",
       " (('я', 'казаться', 'что'), 17),\n",
       " (('у', 'я', 'быть'), 17),\n",
       " (('тридцать', 'третий', 'уровень'), 17),\n",
       " (('выходить', 'из', 'глубина'), 16),\n",
       " (('я', 'не', 'знать'), 16),\n",
       " (('на', 'самый', 'дело'), 15),\n",
       " (('глубинаглубина', 'я', 'не'), 15),\n",
       " (('в', 'виртуальный', 'пространство'), 15),\n",
       " (('я', 'не', 'мочь'), 15),\n",
       " (('но', 'я', 'не'), 15),\n",
       " (('на', 'этот', 'раз'), 14),\n",
       " (('я', 'знать', 'что'), 12),\n",
       " (('я', 'смотреть', 'на'), 12),\n",
       " (('входить', 'в', 'глубина'), 12),\n",
       " (('все', 'в', 'порядок'), 11),\n",
       " (('мочь', 'быть', 'и'), 11),\n",
       " (('то', 'что', 'я'), 11),\n",
       " (('говорить', 'человек', 'без'), 11),\n",
       " (('не', 'в', 'сила'), 11),\n",
       " (('я', 'никогда', 'не'), 11),\n",
       " (('входить', 'в', 'виртуальность'), 10),\n",
       " (('за', 'мой', 'спина'), 10)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_lemmas_trigrams = nltk.ngrams(novel_tokens_lemmas_nopunct, n=3)\n",
    "novel_lemmas_trigrams_stats = Counter(novel_lemmas_trigrams)\n",
    "\n",
    "novel_lemmas_trigrams_stats.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd899e",
   "metadata": {},
   "source": [
    "As one could expect, we find among ngrams both collocations that are frequent in any (fiction) text and some expressions that are characteristic to this very text. The examples of the former are ('я', 'не'), ('мочь', 'быть'), etc. for bigrams, ('на', 'самый', 'дело'), ('все', 'в', 'порядок'), etc. for trigrams; the examples of the latter are ('в', 'глубина'), ('без', 'лицо') for bigrams, ('человек', 'без', 'лицо'), ('я', 'не', 'твой'), etc. for trigrams.\n",
    "\n",
    "Interestingly, most frequent bigrams more often appear to be of the type frequent in any text, while trigrams more often show collocations that in other texts will not be frequent or even will not appear at all.\n",
    "\n",
    "Another thing that is interesting to notice (but that needs further work to be fully established) is that some expressions that are expected in real text seem however to be more frequent than in general. Analyzing such cases may tell something about the text. For example, very high frequency of ('говорить', 'я') means that the text has a lot of dialogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6acafbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 6\n",
    "\n",
    "random.seed(429)\n",
    "\n",
    "sentences = random.sample(nltk.tokenize.sent_tokenize(novel_text.replace('\\n', ' ')), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a50e225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мог быть, сквозь глухую стены сейчас следили за нами отважные эльфы Лориены, но вмешиваться они не станут.\n",
      "Я сделал последнюю попытки уйти в стороны.\n",
      "Вставал снова.\n",
      "Знал чертовски хорошо.\n",
      "— я трогал рукояти мечей.\n",
      "В успехи этого мероприятий я всё же не очень верил.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    new_sentence = []\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        word_parsed = morph.parse(word)[0]\n",
    "        if {'VERB', 'pres'} in word_parsed.tag:\n",
    "            new_word = word_parsed.inflect({'past'}).word\n",
    "        elif {'NOUN', 'sing'} in word_parsed.tag:\n",
    "            new_word = word_parsed.inflect({'plur'}).word\n",
    "        else:\n",
    "            new_word = word\n",
    "        if word[0] == word[0].capitalize():\n",
    "            new_sentence.append(new_word.capitalize())\n",
    "        else:\n",
    "            new_sentence.append(new_word)\n",
    "    print(nltk.tokenize.treebank.TreebankWordDetokenizer().detokenize(new_sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
